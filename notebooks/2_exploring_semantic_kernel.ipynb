{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Semantic Kernel Fundamentals (2025 Edition)\n",
    "\n",
    "This notebook demonstrates Semantic Kernel's core capabilities with 2025 production patterns. We'll explore the stable plugin architecture, modern kernel orchestration, Agent Framework 1.0, and AutoGen integration that showcase SK's enterprise-ready \"Orchestrate Everything\" philosophy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, let's load our environment variables and configure our Azure OpenAI connection for Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded environment from: c:\\Users\\chrismckee\\Documents\\GitHub\\SemanticKernelLangChainComparison\\.env\n",
      "‚úÖ All Azure OpenAI configuration validated successfully\n",
      "Azure OpenAI Configuration for Semantic Kernel:\n",
      "  Endpoint: https://aideveloperaoai.openai.azure.com\n",
      "  Deployment: gpt-4.1\n",
      "  API Version: 2025-01-01-preview\n",
      "  Service ID: azure_chat\n",
      "  API Key: ********************6c6e\n"
     ]
    }
   ],
   "source": [
    "# Environment and configuration setup\n",
    "import os\n",
    "import warnings\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "class SemanticKernelConfig:\n",
    "    \"\"\"Configuration management for Azure OpenAI in Semantic Kernel\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        env_path = find_dotenv()\n",
    "        if env_path:\n",
    "            load_dotenv(env_path)\n",
    "            print(f\"‚úÖ Loaded environment from: {env_path}\")\n",
    "        else:\n",
    "            warnings.warn(\"No .env file found. Using system environment variables only.\")\n",
    "        \n",
    "        self._load_azure_config()\n",
    "        self._validate_config()\n",
    "    \n",
    "    def _load_azure_config(self):\n",
    "        \"\"\"Load Azure OpenAI configuration from environment variables\"\"\"\n",
    "        self.azure_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "        self.azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "        self.azure_deployment = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME', 'gpt-4o-mini')\n",
    "        self.azure_api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "        self.service_id = \"azure_chat\"\n",
    "    \n",
    "    def _validate_config(self):\n",
    "        \"\"\"Validate critical configuration\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if not self.azure_api_key:\n",
    "            errors.append(\"AZURE_OPENAI_API_KEY is required\")\n",
    "        \n",
    "        if not self.azure_endpoint:\n",
    "            errors.append(\"AZURE_OPENAI_ENDPOINT is required\")\n",
    "        \n",
    "        if errors:\n",
    "            raise ValueError(f\"Configuration errors: {', '.join(errors)}\")\n",
    "        \n",
    "        print(\"‚úÖ All Azure OpenAI configuration validated successfully\")\n",
    "    \n",
    "    def display_config(self):\n",
    "        \"\"\"Display current configuration (hiding secrets)\"\"\"\n",
    "        print(\"Azure OpenAI Configuration for Semantic Kernel:\")\n",
    "        print(f\"  Endpoint: {self.azure_endpoint}\")\n",
    "        print(f\"  Deployment: {self.azure_deployment}\")\n",
    "        print(f\"  API Version: {self.azure_api_version}\")\n",
    "        print(f\"  Service ID: {self.service_id}\")\n",
    "        print(f\"  API Key: {'*' * 20 + self.azure_api_key[-4:] if self.azure_api_key else 'Not set'}\")\n",
    "\n",
    "# Initialize configuration\n",
    "try:\n",
    "    sk_config = SemanticKernelConfig()\n",
    "    sk_config.display_config()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load configuration: {e}\")\n",
    "    print(\"\\nPlease ensure you have a .env file with the following variables:\")\n",
    "    print(\"- AZURE_OPENAI_API_KEY\")\n",
    "    print(\"- AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"- AZURE_OPENAI_CHAT_DEPLOYMENT_NAME (optional, defaults to gpt-4o-mini)\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Chat and Kernel Configuration\n",
    "\n",
    "Semantic Kernel uses a dependency injection pattern with services registered in the kernel. This provides strong typing and better enterprise patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Kernel Configuration:\n",
      "  Services registered: 1\n",
      "  Chat service ID: azure_chat\n",
      "üí¨ Basic Chat Example:\n",
      "User > What is the capital of France?\n",
      "Assistant > The capital of France is Paris.\n",
      "\\nUser > What language do they speak there?\n",
      "Assistant > The official language spoken in Paris, France is French.\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "# Initialize the kernel - central orchestrator for all SK operations\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure Azure OpenAI chat completion service with dependency injection\n",
    "azure_chat_service = AzureChatCompletion(\n",
    "    service_id=sk_config.service_id,\n",
    "    deployment_name=sk_config.azure_deployment,\n",
    "    endpoint=sk_config.azure_endpoint,\n",
    "    api_key=sk_config.azure_api_key,\n",
    "    api_version=sk_config.azure_api_version\n",
    ")\n",
    "\n",
    "# Register the service with the kernel (dependency injection pattern)\n",
    "kernel.add_service(azure_chat_service)\n",
    "\n",
    "print(\"üîß Kernel Configuration:\")\n",
    "print(f\"  Services registered: {len(kernel.services)}\")\n",
    "print(f\"  Chat service ID: {sk_config.service_id}\")\n",
    "\n",
    "async def demonstrate_basic_chat():\n",
    "    \"\"\"Demonstrates basic chat functionality with proper settings\"\"\"\n",
    "    \n",
    "    # Create chat history for conversation context\n",
    "    history = ChatHistory()\n",
    "    history.add_system_message(\"You are a helpful assistant who provides concise, step-by-step answers.\")\n",
    "    history.add_user_message(\"What is the capital of France?\")\n",
    "    \n",
    "    # Create execution settings - required for all SK operations\n",
    "    execution_settings = AzureChatPromptExecutionSettings(\n",
    "        service_id=sk_config.service_id,\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(\"üí¨ Basic Chat Example:\")\n",
    "    print(\"User > What is the capital of France?\")\n",
    "    \n",
    "    # Execute the chat completion\n",
    "    response = await azure_chat_service.get_chat_message_content(\n",
    "        chat_history=history, \n",
    "        settings=execution_settings\n",
    "    )\n",
    "    \n",
    "    print(f\"Assistant > {response.content}\")\n",
    "    \n",
    "    # Demonstrate conversation continuation\n",
    "    history.add_assistant_message(response.content)\n",
    "    history.add_user_message(\"What language do they speak there?\")\n",
    "    \n",
    "    print(\"\\nUser > What language do they speak there?\")\n",
    "    \n",
    "    response2 = await azure_chat_service.get_chat_message_content(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings\n",
    "    )\n",
    "    \n",
    "    print(f\"Assistant > {response2.content}\")\n",
    "\n",
    "# Execute the demonstration\n",
    "await demonstrate_basic_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Plugin Architecture and Sequential Orchestration\n",
    "\n",
    "Semantic Kernel's plugin system provides a structured approach to building reusable components. Unlike LangChain's composition, SK uses explicit orchestration."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create semantic functions from prompts (SK's equivalent to LangChain chains)\n# These are registered as plugins in the kernel\nfrom semantic_kernel.prompt_template import PromptTemplateConfig, InputVariable\nfrom semantic_kernel.functions import KernelArguments\n\n# Plugin 1: Company Naming\ncompany_naming_prompt = \"\"\"\nWhat is a good name for a company that makes {{$input}}? \nProvide just the company name, nothing else.\n\"\"\"\n\nnaming_config = PromptTemplateConfig(\n    template=company_naming_prompt,\n    name=\"generate_name\",\n    template_format=\"semantic-kernel\",\n    input_variables=[\n        InputVariable(name=\"input\", description=\"The product description\", is_required=True),\n    ],\n    execution_settings=AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        max_tokens=100,\n        temperature=0.7\n    )\n)\n\nnaming_function = kernel.add_function(\n    function_name=\"generate_name\", \n    plugin_name=\"MarketingPlugin\", \n    prompt_template_config=naming_config,\n)\n\n# Plugin 2: Catchphrase Generation  \ncatchphrase_prompt = \"\"\"\nWrite a creative, memorable catchphrase for the following company: {{$input}}\nMake it catchy and professional. Provide just the catchphrase, nothing else.\n\"\"\"\n\ncatchphrase_config = PromptTemplateConfig(\n    template=catchphrase_prompt,\n    name=\"generate_catchphrase\",\n    template_format=\"semantic-kernel\",\n    input_variables=[\n        InputVariable(name=\"input\", description=\"The company name\", is_required=True),\n    ],\n    execution_settings=AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        max_tokens=100,\n        temperature=0.8\n    )\n)\n\ncatchphrase_function = kernel.add_function(\n    function_name=\"generate_catchphrase\", \n    plugin_name=\"MarketingPlugin\", \n    prompt_template_config=catchphrase_config,\n)\n\nprint(\"üîå Plugins Registered:\")\nprint(f\"  Total plugins: {len(kernel.plugins)}\")\nfor plugin_name, plugin in kernel.plugins.items():\n    print(f\"  - {plugin_name}: {len(plugin.functions)} functions\")\n    for func_name in plugin.functions:\n        print(f\"    ‚Ä¢ {func_name}\")\n\nasync def demonstrate_orchestration():\n    \"\"\"Demonstrates explicit orchestration - SK's approach to sequential processing\"\"\"\n    \n    product = \"colorful, eco-friendly socks\"\n    print(f\"\\\\nüéØ Input product: {product}\")\n    print(\"\\\\nüîó Running Sequential Orchestration...\")\n    \n    # Step 1: Generate company name (explicit orchestration)\n    print(\"\\\\nüìù Step 1: Generating company name...\")\n    try:\n        name_result = await kernel.invoke(naming_function, KernelArguments(input=product))\n        company_name = str(name_result).strip()\n        print(f\"   Result: {company_name}\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return\n    \n    # Step 2: Generate catchphrase using the generated name\n    print(\"\\\\nüé® Step 2: Generating catchphrase...\")\n    try:\n        catchphrase_result = await kernel.invoke(catchphrase_function, KernelArguments(input=company_name))\n        catchphrase = str(catchphrase_result).strip()\n        print(f\"   Result: {catchphrase}\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return\n    \n    # Display final results\n    print(\"\\\\n\" + \"=\"*50)\n    print(\"‚úÖ ORCHESTRATION COMPLETE\")\n    print(\"=\"*50)\n    print(f\"Product: {product}\")\n    print(f\"Company Name: {company_name}\")\n    print(f\"Catchphrase: {catchphrase}\")\n    print(\"=\"*50)\n    \n    return {\n        \"product\": product,\n        \"company_name\": company_name, \n        \"catchphrase\": catchphrase\n    }\n\n# Execute the orchestration\nresult = await demonstrate_orchestration()\n\n# Demonstrate plugin reusability\nprint(\"\\\\nüîÑ Demonstrating Plugin Reusability...\")\ntest_products = [\"smart home devices\", \"artisanal coffee beans\"]\n\nfor product in test_products:\n    print(f\"\\\\n‚Üí Testing with: {product}\")\n    name_result = await kernel.invoke(naming_function, KernelArguments(input=product))\n    print(f\"  Generated name: {name_result}\")"
  },
  {
   "cell_type": "markdown",
   "id": "ynixtlvl6i",
   "metadata": {},
   "source": "### 2.3 Native Function Plugins with @kernel_function Decorator\n\n**What this does:** Creates Python classes with the `@kernel_function` decorator to combine traditional code with AI capabilities, demonstrating Semantic Kernel's hybrid AI + code approach.\n\nThe code below shows how to build structured, discoverable plugins:\n- **Plugin classes** using Python classes with decorated methods for reusable components\n- **Function metadata** with descriptions and type annotations for AI discoverability  \n- **Parameter descriptions** using `Annotated` types to help the AI understand function inputs\n- **Plugin registration** adding multiple plugin instances to the kernel's function registry\n- **Direct invocation** calling native functions with proper argument handling\n\n**Native Plugin Benefits:**\n- üîß **Hybrid AI + Code** - Seamlessly blend LLM capabilities with traditional programming\n- üìñ **Self-documenting** - Rich metadata helps AI understand capabilities and usage\n- üéØ **Type safety** - Python type hints provide compile-time validation\n- üîÑ **Reusable** - Plugin classes can be instantiated and shared across kernels\n\n**Azure Alternative:** Azure Functions provide similar serverless compute capabilities, though Semantic Kernel's native plugins offer tighter AI integration and automatic discoverability.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "native-functions-demo",
   "metadata": {},
   "outputs": [],
   "source": "import random\nfrom semantic_kernel.functions import kernel_function, KernelArguments\nfrom datetime import datetime, timedelta\nimport json\nfrom typing import Annotated\n\n# Native function plugins demonstrate Semantic Kernel's hybrid AI + code approach\n# These are Python classes with @kernel_function decorated methods\n\nclass MathPlugin:\n    \"\"\"Plugin demonstrating mathematical operations with rich metadata\"\"\"\n    \n    @kernel_function(\n        description=\"Generate a random number within specified bounds for simulations\",\n        name=\"GenerateRandomNumber\"\n    )\n    def generate_random_number(\n        self, \n        min_val: Annotated[int, \"Minimum value (inclusive)\"] = 1, \n        max_val: Annotated[int, \"Maximum value (inclusive)\"] = 100\n    ) -> Annotated[str, \"Random number as string\"]:\n        \"\"\"Generate a random number between specified bounds with error handling\"\"\"\n        try:\n            result = random.randint(min_val, max_val)\n            return str(result)\n        except ValueError as e:\n            return f\"Error: Invalid range - {e}\"\n    \n    @kernel_function(\n        description=\"Calculate percentage for analytics and reporting\",\n        name=\"CalculatePercentage\"\n    )\n    def calculate_percentage(\n        self, \n        part: Annotated[float, \"Part value (numerator)\"], \n        whole: Annotated[float, \"Whole value (denominator)\"]\n    ) -> Annotated[str, \"Percentage formatted as string with % symbol\"]:\n        \"\"\"Calculate percentage with proper error handling for division by zero\"\"\"\n        try:\n            if whole == 0:\n                return \"Error: Cannot divide by zero\"\n            percentage = (part / whole) * 100\n            return f\"{percentage:.2f}%\"\n        except Exception as e:\n            return f\"Error in calculation: {e}\"\n\nclass TimePlugin:\n    \"\"\"Plugin for date and time operations with business logic\"\"\"\n    \n    @kernel_function(\n        description=\"Get current date and time in standard format\",\n        name=\"GetCurrentDateTime\"\n    )\n    def get_current_datetime(self) -> Annotated[str, \"Current date and time in YYYY-MM-DD HH:MM:SS format\"]:\n        \"\"\"Returns current date and time in standardized format\"\"\"\n        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    \n    @kernel_function(\n        description=\"Calculate future or past dates by adding days (use negative for past)\",\n        name=\"AddDaysToDate\"\n    )\n    def add_days_to_date(\n        self, \n        days: Annotated[int, \"Number of days to add (negative for past dates)\"]\n    ) -> Annotated[str, \"Future/past date in YYYY-MM-DD format\"]:\n        \"\"\"Calculate future or past dates with robust error handling\"\"\"\n        try:\n            target_date = datetime.now() + timedelta(days=days)\n            return target_date.strftime(\"%Y-%m-%d\")\n        except (OverflowError, ValueError) as e:\n            return f\"Error: Invalid date calculation - {e}\"\n\nclass DataPlugin:\n    \"\"\"Plugin for data processing with enterprise-ready functions\"\"\"\n    \n    @kernel_function(\n        description=\"Extract specific field from JSON data with validation\",\n        name=\"ExtractJsonField\"\n    )\n    def extract_json_field(\n        self, \n        json_data: Annotated[str, \"JSON string to parse\"], \n        field_name: Annotated[str, \"Field name to extract from JSON\"]\n    ) -> Annotated[str, \"Extracted field value or error message\"]:\n        \"\"\"Extract field from JSON with comprehensive error handling\"\"\"\n        try:\n            data = json.loads(json_data)\n            if field_name in data:\n                return str(data[field_name])\n            else:\n                available_fields = \", \".join(data.keys())\n                return f\"Field '{field_name}' not found. Available fields: {available_fields}\"\n        except json.JSONDecodeError as e:\n            return f\"Error: Invalid JSON format - {e}\"\n        except Exception as e:\n            return f\"Error processing JSON: {e}\"\n    \n    @kernel_function(\n        description=\"Count words in text for content analysis\",\n        name=\"CountWords\"\n    )\n    def count_words(\n        self, \n        text: Annotated[str, \"Text content to analyze\"]\n    ) -> Annotated[str, \"Word count as string\"]:\n        \"\"\"Count words with whitespace handling and validation\"\"\"\n        try:\n            if not text or not text.strip():\n                return \"0\"\n            word_count = len(text.split())\n            return str(word_count)\n        except Exception as e:\n            return f\"Error counting words: {e}\"\n\n# Register plugins with the kernel - demonstrating plugin discovery\nprint(\"üîß Registering Native Function Plugins...\")\n\nmath_plugin = kernel.add_plugin(MathPlugin(), \"MathPlugin\")\ntime_plugin = kernel.add_plugin(TimePlugin(), \"TimePlugin\") \ndata_plugin = kernel.add_plugin(DataPlugin(), \"DataPlugin\")\n\nprint(f\"‚úÖ Successfully registered {len(kernel.plugins)} plugins\")\n\n# Display plugin metadata for AI discoverability\nprint(\"\\nüìã Plugin Registry (AI can discover these capabilities):\")\nfor plugin_name, plugin in kernel.plugins.items():\n    print(f\"\\n  üì¶ {plugin_name}:\")\n    for func_name, func in plugin.functions.items():\n        print(f\"    ‚Ä¢ {func_name}: {func.description}\")\n        # Show parameter details for complex functions\n        if hasattr(func, 'metadata') and func.metadata.parameters:\n            for param in func.metadata.parameters:\n                print(f\"      - {param.name}: {param.description}\")\n\n# Demonstrate direct native function invocation\nasync def demonstrate_native_plugin_architecture():\n    \"\"\"Showcase native plugin capabilities and metadata-driven AI interaction\"\"\"\n    \n    print(\"\\nüöÄ Testing Native Plugin Architecture:\")\n    print(\"=\" * 60)\n    \n    # Test MathPlugin with error handling\n    print(\"\\nüßÆ MathPlugin Capabilities:\")\n    try:\n        # Valid range\n        random_result = await kernel.invoke(\n            math_plugin[\"GenerateRandomNumber\"], \n            KernelArguments(min_val=10, max_val=50)\n        )\n        print(f\"  ‚úÖ Random number (10-50): {random_result}\")\n        \n        # Percentage calculation\n        percentage_result = await kernel.invoke(\n            math_plugin[\"CalculatePercentage\"],\n            KernelArguments(part=75, whole=200)\n        )\n        print(f\"  ‚úÖ 75 out of 200: {percentage_result}\")\n        \n        # Error case - invalid range\n        error_result = await kernel.invoke(\n            math_plugin[\"GenerateRandomNumber\"],\n            KernelArguments(min_val=100, max_val=50)\n        )\n        print(f\"  ‚ö†Ô∏è Error handling: {error_result}\")\n        \n    except Exception as e:\n        print(f\"  ‚ùå Plugin error: {e}\")\n    \n    # Test TimePlugin\n    print(\"\\nüìÖ TimePlugin Capabilities:\")\n    try:\n        current_time = await kernel.invoke(time_plugin[\"GetCurrentDateTime\"])\n        print(f\"  ‚úÖ Current time: {current_time}\")\n        \n        future_date = await kernel.invoke(\n            time_plugin[\"AddDaysToDate\"],\n            KernelArguments(days=14)\n        )\n        print(f\"  ‚úÖ Date in 14 days: {future_date}\")\n        \n        past_date = await kernel.invoke(\n            time_plugin[\"AddDaysToDate\"],\n            KernelArguments(days=-30)\n        )\n        print(f\"  ‚úÖ Date 30 days ago: {past_date}\")\n        \n    except Exception as e:\n        print(f\"  ‚ùå Plugin error: {e}\")\n    \n    # Test DataPlugin with real-world scenarios\n    print(\"\\nüîç DataPlugin Capabilities:\")\n    try:\n        # Valid JSON extraction\n        sample_json = '{\"name\": \"Alice Smith\", \"age\": 32, \"department\": \"Engineering\", \"city\": \"Seattle\"}'\n        \n        name_result = await kernel.invoke(\n            data_plugin[\"ExtractJsonField\"],\n            KernelArguments(json_data=sample_json, field_name=\"department\")\n        )\n        print(f\"  ‚úÖ Extracted department: {name_result}\")\n        \n        # Missing field case\n        missing_result = await kernel.invoke(\n            data_plugin[\"ExtractJsonField\"],\n            KernelArguments(json_data=sample_json, field_name=\"salary\")\n        )\n        print(f\"  ‚ö†Ô∏è Missing field: {missing_result}\")\n        \n        # Word count analysis\n        content = \"Semantic Kernel provides a powerful plugin architecture for enterprise applications\"\n        word_count = await kernel.invoke(\n            data_plugin[\"CountWords\"],\n            KernelArguments(text=content)\n        )\n        print(f\"  ‚úÖ Word count: {word_count} words\")\n        \n    except Exception as e:\n        print(f\"  ‚ùå Plugin error: {e}\")\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"‚úÖ Native Plugin Architecture Demonstration Complete\")\n    print(\"üí° Key Benefits:\")\n    print(\"   ‚Ä¢ Rich metadata enables AI function discovery\")\n    print(\"   ‚Ä¢ Type annotations provide safety and clarity\") \n    print(\"   ‚Ä¢ Error handling ensures robust operation\")\n    print(\"   ‚Ä¢ Reusable plugin classes promote modularity\")\n\n# Execute the native plugin demonstration\nawait demonstrate_native_plugin_architecture()"
  },
  {
   "cell_type": "markdown",
   "id": "6alcrpf8no5",
   "metadata": {},
   "source": "### 2.4 Advanced Function Calling with FunctionChoiceBehavior\n\n**What this does:** Demonstrates Semantic Kernel's advanced function calling capabilities using `FunctionChoiceBehavior` to control exactly how and when the AI model selects and invokes functions.\n\nThe code below shows three distinct function calling strategies:\n- **AUTO mode** - AI automatically chooses from available functions based on context\n- **REQUIRED mode** - Forces AI to call specific functions, ensuring tool usage\n- **NONE mode** - Disables function calling while keeping functions visible to the model\n- **Selective function control** - Explicitly defining which functions are available for each behavior\n- **Advanced configuration** - Concurrent invocation and parallel calling options\n\n**Function Choice Benefits:**\n- üéØ **Precise control** - Choose exactly which functions the AI can access\n- ‚ö° **Performance optimization** - Concurrent and parallel function execution  \n- üõ°Ô∏è **Safety management** - Prevent unintended function calls in sensitive contexts\n- üìä **Behavior prediction** - Reliable function calling patterns for production use\n\n**Azure Alternative:** Azure AI services support function calling, though Semantic Kernel's FunctionChoiceBehavior provides more granular control and advanced configuration options for enterprise scenarios.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "46mgpjg1awt",
   "source": "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\nfrom semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehaviorOptions\n\n# Advanced Function Calling demonstrates precise control over AI function selection\n# This showcases the three FunctionChoiceBehavior modes: AUTO, REQUIRED, NONE\n\nasync def demonstrate_advanced_function_calling():\n    \"\"\"Showcase FunctionChoiceBehavior patterns for production AI applications\"\"\"\n    \n    print(\"üéØ Advanced Function Calling with FunctionChoiceBehavior\")\n    print(\"=\" * 70)\n    \n    # Scenario 1: AUTO - AI chooses functions automatically based on context\n    print(\"\\nü§ñ Scenario 1: AUTO Function Choice Behavior\")\n    print(\"   ‚Ä¢ AI automatically selects appropriate functions\")\n    print(\"   ‚Ä¢ Most flexible mode for general-purpose applications\")\n    \n    auto_settings = AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        function_choice_behavior=FunctionChoiceBehavior.Auto(),\n        max_tokens=200,\n        temperature=0.3\n    )\n    \n    # Create chat history for function calling\n    auto_history = ChatHistory()\n    auto_history.add_system_message(\n        \"You are a helpful assistant with access to math, time, and data processing tools. \"\n        \"Use the appropriate functions when needed to answer user questions accurately.\"\n    )\n    auto_history.add_user_message(\n        \"What's the current date and time? Also, what's 25% of 400?\"\n    )\n    \n    try:\n        print(\"   üîÑ Processing with AUTO behavior...\")\n        auto_response = await azure_chat_service.get_chat_message_content(\n            chat_history=auto_history,\n            settings=auto_settings,\n            kernel=kernel\n        )\n        print(f\"   ‚úÖ AUTO Response: {auto_response.content}\")\n        \n        # Check if functions were called\n        if hasattr(auto_response, 'items') and auto_response.items:\n            function_calls = [item for item in auto_response.items if hasattr(item, 'function_name')]\n            if function_calls:\n                print(f\"   üîß Functions called: {[f.function_name for f in function_calls]}\")\n        \n    except Exception as e:\n        print(f\"   ‚ùå AUTO mode error: {e}\")\n    \n    # Scenario 2: REQUIRED - Force AI to use specific functions\n    print(\"\\nüéØ Scenario 2: REQUIRED Function Choice Behavior\")\n    print(\"   ‚Ä¢ Forces AI to call specified functions\")\n    print(\"   ‚Ä¢ Ensures tool usage for critical operations\")\n    \n    # Specify which functions must be used\n    required_functions = [\n        time_plugin[\"GetCurrentDateTime\"],\n        math_plugin[\"CalculatePercentage\"]\n    ]\n    \n    required_settings = AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        function_choice_behavior=FunctionChoiceBehavior.Required(\n            functions=required_functions,\n            options=FunctionChoiceBehaviorOptions(\n                allow_concurrent_invocation=True  # Enable concurrent execution\n            )\n        ),\n        max_tokens=200,\n        temperature=0.3\n    )\n    \n    required_history = ChatHistory()\n    required_history.add_system_message(\n        \"You must use the available functions to provide accurate information. \"\n        \"Always call the required functions to answer user questions.\"\n    )\n    required_history.add_user_message(\n        \"I need to know what time it is and calculate 40% of 250.\"\n    )\n    \n    try:\n        print(\"   üîÑ Processing with REQUIRED behavior...\")\n        required_response = await azure_chat_service.get_chat_message_content(\n            chat_history=required_history,\n            settings=required_settings,\n            kernel=kernel\n        )\n        print(f\"   ‚úÖ REQUIRED Response: {required_response.content}\")\n        print(\"   üí° Notice: AI was forced to use the specified functions\")\n        \n    except Exception as e:\n        print(f\"   ‚ùå REQUIRED mode error: {e}\")\n    \n    # Scenario 3: NONE - Disable function calling\n    print(\"\\nüö´ Scenario 3: NONE Function Choice Behavior\")\n    print(\"   ‚Ä¢ Disables all function calling\")\n    print(\"   ‚Ä¢ AI knows about functions but cannot invoke them\")\n    \n    none_settings = AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        function_choice_behavior=FunctionChoiceBehavior.None(),\n        max_tokens=200,\n        temperature=0.7\n    )\n    \n    none_history = ChatHistory()\n    none_history.add_system_message(\n        \"You are a helpful assistant. You can see available functions but cannot call them. \"\n        \"Explain what you would do if you could use the functions.\"\n    )\n    none_history.add_user_message(\n        \"What's today's date and what's 30% of 150? Show me how you would solve this.\"\n    )\n    \n    try:\n        print(\"   üîÑ Processing with NONE behavior...\")\n        none_response = await azure_chat_service.get_chat_message_content(\n            chat_history=none_history,\n            settings=none_settings,\n            kernel=kernel\n        )\n        print(f\"   ‚úÖ NONE Response: {none_response.content}\")\n        print(\"   üí° Notice: AI explains what it would do but cannot call functions\")\n        \n    except Exception as e:\n        print(f\"   ‚ùå NONE mode error: {e}\")\n    \n    # Scenario 4: Selective Function Control\n    print(\"\\nüéõÔ∏è Scenario 4: Selective Function Control\")\n    print(\"   ‚Ä¢ Choose specific functions for specific contexts\")\n    print(\"   ‚Ä¢ Fine-grained control over available capabilities\")\n    \n    # Only allow time-related functions for this scenario\n    time_only_functions = [\n        time_plugin[\"GetCurrentDateTime\"],\n        time_plugin[\"AddDaysToDate\"]\n    ]\n    \n    selective_settings = AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        function_choice_behavior=FunctionChoiceBehavior.Auto(\n            functions=time_only_functions,\n            options=FunctionChoiceBehaviorOptions(\n                allow_concurrent_invocation=False,  # Sequential execution\n                allow_parallel_calls=False  # One function at a time\n            )\n        ),\n        max_tokens=200,\n        temperature=0.5\n    )\n    \n    selective_history = ChatHistory()\n    selective_history.add_system_message(\n        \"You are a scheduling assistant with access to time-related functions only. \"\n        \"Help users with date and time calculations.\"\n    )\n    selective_history.add_user_message(\n        \"What's today's date? Also, what date will it be in 15 days? \"\n        \"And can you calculate 25% of 100?\"  # This should not trigger math functions\n    )\n    \n    try:\n        print(\"   üîÑ Processing with selective function control...\")\n        selective_response = await azure_chat_service.get_chat_message_content(\n            chat_history=selective_history,\n            settings=selective_settings,\n            kernel=kernel\n        )\n        print(f\"   ‚úÖ Selective Response: {selective_response.content}\")\n        print(\"   üí° Notice: Only time functions available, math request handled differently\")\n        \n    except Exception as e:\n        print(f\"   ‚ùå Selective mode error: {e}\")\n    \n    # Advanced Configuration Demo\n    print(\"\\n‚öôÔ∏è Advanced Configuration Options:\")\n    print(\"   üîß Concurrent Invocation: Execute multiple functions simultaneously\")\n    print(\"   üìä Parallel Calls: Allow AI to select multiple functions in one request\")\n    print(\"   üéØ Function Lists: Specify exactly which functions are available\")\n    print(\"   üõ°Ô∏è Safety Controls: Prevent unauthorized function access\")\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"‚úÖ Advanced Function Calling Demonstration Complete\")\n    print(\"\\nüí° Key Takeaways:\")\n    print(\"   ‚Ä¢ AUTO: Maximum flexibility, AI chooses best functions\")\n    print(\"   ‚Ä¢ REQUIRED: Guaranteed function usage, predictable behavior\")\n    print(\"   ‚Ä¢ NONE: Information only, no function execution\")\n    print(\"   ‚Ä¢ Selective: Precise control over available capabilities\")\n    print(\"   ‚Ä¢ Options: Fine-tune execution behavior for production needs\")\n\n# Execute the advanced function calling demonstration\nawait demonstrate_advanced_function_calling()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Semantic Kernel Fundamentals\n",
    "\n",
    "This notebook covered Semantic Kernel's core concepts using enterprise-ready patterns:\n",
    "\n",
    "### Key Concepts Learned:\n",
    "1. **Kernel Architecture**: Central orchestrator with dependency injection and service registration\n",
    "2. **Plugin System**: Structured approach combining semantic functions (AI) and native functions (code)\n",
    "3. **Explicit Orchestration**: Programmatic control flow rather than compositional chaining\n",
    "4. **Function Calling**: Automatic function selection with typed interfaces and safety\n",
    "\n",
    "### Semantic Kernel's Philosophy:\n",
    "- **\"Orchestrate Everything\"**: Structured orchestration with clear separation of concerns\n",
    "- **Hybrid AI + Code**: Seamless integration of LLM capabilities with traditional programming\n",
    "- **Enterprise Patterns**: Dependency injection, typed interfaces, and governance-ready architecture\n",
    "- **Plugin Ecosystem**: Reusable, discoverable functions with proper metadata\n",
    "\n",
    "### SK vs LangChain Comparison:\n",
    "| Aspect | LangChain (LCEL) | Semantic Kernel |\n",
    "|--------|------------------|-----------------|\n",
    "| **Composition** | Pipe operators (`\\|`) | Explicit `kernel.invoke()` calls |\n",
    "| **Functions** | Tools with dynamic binding | Plugins with typed interfaces |\n",
    "| **Flow Control** | Implicit through chains | Explicit orchestration code |\n",
    "| **Enterprise Focus** | Community-driven | Microsoft enterprise patterns |\n",
    "\n",
    "### Next Steps:\n",
    "- **Multi-Agent Systems**: See `4_semantic_kernel_agents.ipynb` for Agent Framework\n",
    "- **Advanced Plugins**: Memory integration, planning, and complex workflows\n",
    "- **Production Deployment**: Azure integration, monitoring, and governance\n",
    "\n",
    "### Production Considerations:\n",
    "- Leverage dependency injection for testability and maintainability\n",
    "- Use typed interfaces for better IDE support and error prevention\n",
    "- Implement proper error handling and logging throughout the kernel\n",
    "- Consider plugin security and validation for production deployments\n",
    "- Take advantage of Azure ecosystem integration for enterprise features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is being removed - duplicate content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-framework-2025",
   "metadata": {},
   "source": [
    "## üöÄ 2025 Agent Framework 1.0 Preview\n",
    "\n",
    "Semantic Kernel's Agent Framework is moving to GA in Q1 2025. Here's a preview of the stable production patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent-framework-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025 PATTERN: Agent Framework 1.0 stable API patterns\n",
    "try:\n",
    "    from semantic_kernel.agents import ChatCompletionAgent\n",
    "    from semantic_kernel.agents.group_chat import AgentGroupChat\n",
    "    from semantic_kernel.contents import ChatMessageContent, AuthorRole\n",
    "    \n",
    "    print(\"‚úÖ Agent Framework 1.0 available (preview mode)\")\n",
    "    \n",
    "    # Create agents with stable 1.0 API patterns\n",
    "    research_agent = ChatCompletionAgent(\n",
    "        service_id=sk_config.service_id,\n",
    "        kernel=kernel,\n",
    "        name=\"ResearchSpecialist\",\n",
    "        instructions=\"You are a research specialist who provides detailed, well-sourced information on any topic.\"\n",
    "    )\n",
    "    \n",
    "    analysis_agent = ChatCompletionAgent(\n",
    "        service_id=sk_config.service_id,\n",
    "        kernel=kernel,\n",
    "        name=\"DataAnalyst\", \n",
    "        instructions=\"You are a data analyst who interprets research findings and provides actionable insights.\"\n",
    "    )\n",
    "    \n",
    "    # Create agent group chat for collaboration\n",
    "    agent_chat = AgentGroupChat(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        termination_strategy=None  # Will run until completion\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Agent Framework Status:\")\n",
    "    print(f\"   Agents created: {len(agent_chat.agents)}\")\n",
    "    print(f\"   Research Agent: {research_agent.name}\")\n",
    "    print(f\"   Analysis Agent: {analysis_agent.name}\")\n",
    "    \n",
    "    # Demonstrate agent collaboration\n",
    "    async def demonstrate_agent_collaboration():\n",
    "        \"\"\"Shows how agents collaborate using the 2025 stable API\"\"\"\n",
    "        \n",
    "        user_message = ChatMessageContent(\n",
    "            role=AuthorRole.USER,\n",
    "            content=\"Research the benefits of renewable energy and provide an analysis of adoption trends.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüéØ User Request: {user_message.content}\")\n",
    "        print(\"\\nü§ñ Agent Collaboration in Progress...\")\n",
    "        \n",
    "        # Add user message to chat\n",
    "        await agent_chat.add_chat_message(user_message)\n",
    "        \n",
    "        # Execute agent collaboration\n",
    "        async for message in agent_chat.invoke():\n",
    "            print(f\"\\n[{message.author.name}]: {message.content}\")\n",
    "            \n",
    "            # Limit output for demo\n",
    "            if len(agent_chat.history) >= 4:  # User + 2 agent responses\n",
    "                break\n",
    "    \n",
    "    # Run the collaboration demo\n",
    "    await demonstrate_agent_collaboration()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Agent Framework not available in current version: {e}\")\n",
    "    print(\"üìÖ Agent Framework 1.0 GA expected Q1 2025\")\n",
    "    print(\"üí° Install preview: pip install semantic-kernel --pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autogen-integration",
   "metadata": {},
   "source": [
    "## üîó 2025 AutoGen Integration\n",
    "\n",
    "Microsoft is providing three convergence approaches for AutoGen + Semantic Kernel integration in early 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "autogen-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025 PATTERN: AutoGen integration with Semantic Kernel\n",
    "try:\n",
    "    # Install: pip install semantic-kernel[autogen]\n",
    "    from semantic_kernel.agents.autogen import AutoGenAgent\n",
    "    \n",
    "    print(\"‚úÖ AutoGen integration available\")\n",
    "    \n",
    "    # Create AutoGen conversable agent within SK ecosystem\n",
    "    autogen_research_agent = AutoGenAgent(\n",
    "        kernel=kernel,\n",
    "        name=\"AutoGenResearcher\",\n",
    "        system_message=\"You are an advanced research agent with deep analytical capabilities.\",\n",
    "        llm_config={\n",
    "            'model': sk_config.azure_deployment,\n",
    "            'temperature': 0.7,\n",
    "            'azure_endpoint': sk_config.azure_endpoint,\n",
    "            'api_key': sk_config.azure_api_key\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"üî¨ AutoGen Agent Created:\")\n",
    "    print(f\"   Name: {autogen_research_agent.name}\")\n",
    "    print(f\"   Type: AutoGen Conversable Agent in SK Runtime\")\n",
    "    \n",
    "    # Demonstrate seamless integration\n",
    "    async def demonstrate_autogen_integration():\n",
    "        \"\"\"Shows AutoGen agents working within SK ecosystem\"\"\"\n",
    "        \n",
    "        # Use AutoGen agent in SK Agent Framework\n",
    "        mixed_chat = AgentGroupChat(\n",
    "            agents=[autogen_research_agent, analysis_agent],  # Mix of AutoGen + SK agents\n",
    "            termination_strategy=None\n",
    "        )\n",
    "        \n",
    "        user_message = ChatMessageContent(\n",
    "            role=AuthorRole.USER,\n",
    "            content=\"Analyze the future of AI agent frameworks and provide strategic recommendations.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüéØ Mixed Agent Team Task: {user_message.content}\")\n",
    "        print(\"\\nü§ù AutoGen + SK Agent Collaboration...\")\n",
    "        \n",
    "        await mixed_chat.add_chat_message(user_message)\n",
    "        \n",
    "        # Show first few exchanges\n",
    "        response_count = 0\n",
    "        async for message in mixed_chat.invoke():\n",
    "            print(f\"\\n[{message.author.name}]: {message.content[:200]}...\")\n",
    "            response_count += 1\n",
    "            if response_count >= 2:  # Limit for demo\n",
    "                break\n",
    "    \n",
    "    # Run the mixed integration demo\n",
    "    await demonstrate_autogen_integration()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è AutoGen integration not available: {e}\")\n",
    "    print(\"üìÖ AutoGen integration available early 2025\")\n",
    "    print(\"üí° Install when available: pip install semantic-kernel[autogen]\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è AutoGen integration error: {e}\")\n",
    "    print(\"üìù Note: AutoGen integration is in active development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-framework-preview",
   "metadata": {},
   "source": [
    "## ‚ö° 2025 Process Framework Preview\n",
    "\n",
    "Process Framework GA is expected Q2 2025 for stateful workflows and business process automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-framework-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025 PATTERN: Process Framework preview for business workflows\n",
    "try:\n",
    "    from semantic_kernel.processes import Process, ProcessStep\n",
    "    \n",
    "    print(\"‚úÖ Process Framework preview available\")\n",
    "    \n",
    "    # Define workflow steps\n",
    "    class DocumentAnalysisStep(ProcessStep):\n",
    "        async def execute(self, context):\n",
    "            \"\"\"Analyze document content\"\"\"\n",
    "            print(f\"üìÑ Analyzing document: {context.input}\")\n",
    "            # Simulate document analysis\n",
    "            return f\"Analysis complete for {context.input}\"\n",
    "    \n",
    "    class QualityReviewStep(ProcessStep):\n",
    "        async def execute(self, context):\n",
    "            \"\"\"Quality review step\"\"\"\n",
    "            print(f\"üîç Quality review: {context.data}\")\n",
    "            # Simulate human-in-the-loop review\n",
    "            return \"Quality review passed\"\n",
    "    \n",
    "    # Create stateful process\n",
    "    document_process = Process(\n",
    "        steps=[\n",
    "            DocumentAnalysisStep(),\n",
    "            QualityReviewStep(),\n",
    "        ],\n",
    "        orchestration_mode='sequential'\n",
    "    )\n",
    "    \n",
    "    print(f\"üîÑ Process Framework Demo:\")\n",
    "    print(f\"   Steps defined: {len(document_process.steps)}\")\n",
    "    print(f\"   Orchestration: {document_process.orchestration_mode}\")\n",
    "    \n",
    "    # Execute process workflow\n",
    "    async def demonstrate_process_workflow():\n",
    "        \"\"\"Shows stateful business process execution\"\"\"\n",
    "        \n",
    "        input_document = \"Technical Requirements Document v2.1\"\n",
    "        print(f\"\\nüéØ Processing: {input_document}\")\n",
    "        \n",
    "        result = await document_process.run(input_document)\n",
    "        print(f\"‚úÖ Process completed: {result}\")\n",
    "    \n",
    "    # Run the process demo\n",
    "    await demonstrate_process_workflow()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Process Framework not available: {e}\")\n",
    "    print(\"üìÖ Process Framework GA expected Q2 2025\")\n",
    "    print(\"üí° Install preview: pip install semantic-kernel --pre\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Process Framework error: {e}\")\n",
    "    print(\"üìù Note: Process Framework is in active development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Semantic Kernel Fundamentals (2025 Edition)\n",
    "\n",
    "This notebook covered the core concepts of Semantic Kernel with 2025 production patterns:\n",
    "\n",
    "### Key Concepts Learned:\n",
    "1. **Plugin Architecture**: Structured, reusable components with explicit orchestration\n",
    "2. **Kernel Orchestration**: Central dependency injection and service management\n",
    "3. **Function Calling**: Automatic function invocation with structured data flows\n",
    "4. **Agent Framework 1.0**: Production-ready multi-agent collaboration (Q1 2025 GA)\n",
    "5. **AutoGen Integration**: Seamless transition from experimentation to production\n",
    "6. **Process Framework**: Stateful workflows and business process automation (Q2 2025 GA)\n",
    "\n",
    "### 2025 Semantic Kernel Evolution:\n",
    "- **Agent Framework 1.0**: Stable API for production multi-agent systems\n",
    "- **AutoGen Convergence**: Three integration approaches for enhanced capabilities\n",
    "- **Process Framework**: Enterprise workflow automation with human-in-the-loop\n",
    "- **Production Readiness**: Enterprise governance and compliance features\n",
    "- **Azure Integration**: Enhanced cloud-native capabilities\n",
    "\n",
    "### Next Steps:\n",
    "- **Advanced Agents**: See `4_semantic_kernel_agents.ipynb` for complex agent patterns\n",
    "- **Production Deployment**: Enterprise governance and monitoring setup\n",
    "- **AutoGen Migration**: Transition strategies from pure AutoGen to SK\n",
    "- **Process Automation**: Business workflow implementation patterns\n",
    "\n",
    "### 2025 Production Considerations:\n",
    "- Prepare for Agent Framework 1.0 GA in Q1 2025\n",
    "- Evaluate AutoGen integration options for advanced agent capabilities\n",
    "- Plan Process Framework adoption for workflow automation in Q2 2025\n",
    "- Implement enterprise governance and compliance patterns\n",
    "- Leverage Azure integration for cloud-native deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}