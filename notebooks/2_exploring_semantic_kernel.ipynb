{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 2: Semantic Kernel Fundamentals\n\nThis notebook demonstrates Semantic Kernel's core capabilities using Azure OpenAI. We'll explore the plugin architecture, kernel orchestration, and structured function calling that showcase SK's \"Orchestrate Everything\" philosophy.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, let's load our environment variables and configure our Azure OpenAI connection for Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and configuration setup\n",
    "import os\n",
    "import warnings\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "class SemanticKernelConfig:\n",
    "    \"\"\"Configuration management for Azure OpenAI in Semantic Kernel\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        env_path = find_dotenv()\n",
    "        if env_path:\n",
    "            load_dotenv(env_path)\n",
    "            print(f\"‚úÖ Loaded environment from: {env_path}\")\n",
    "        else:\n",
    "            warnings.warn(\"No .env file found. Using system environment variables only.\")\n",
    "        \n",
    "        self._load_azure_config()\n",
    "        self._validate_config()\n",
    "    \n",
    "    def _load_azure_config(self):\n",
    "        \"\"\"Load Azure OpenAI configuration from environment variables\"\"\"\n",
    "        self.azure_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "        self.azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "        self.azure_deployment = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME', 'gpt-4o-mini')\n",
    "        self.azure_api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2024-10-21')\n",
    "        self.service_id = \"azure_chat\"\n",
    "    \n",
    "    def _validate_config(self):\n",
    "        \"\"\"Validate critical configuration\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if not self.azure_api_key:\n",
    "            errors.append(\"AZURE_OPENAI_API_KEY is required\")\n",
    "        \n",
    "        if not self.azure_endpoint:\n",
    "            errors.append(\"AZURE_OPENAI_ENDPOINT is required\")\n",
    "        \n",
    "        if errors:\n",
    "            raise ValueError(f\"Configuration errors: {', '.join(errors)}\")\n",
    "        \n",
    "        print(\"‚úÖ All Azure OpenAI configuration validated successfully\")\n",
    "    \n",
    "    def display_config(self):\n",
    "        \"\"\"Display current configuration (hiding secrets)\"\"\"\n",
    "        print(\"Azure OpenAI Configuration for Semantic Kernel:\")\n",
    "        print(f\"  Endpoint: {self.azure_endpoint}\")\n",
    "        print(f\"  Deployment: {self.azure_deployment}\")\n",
    "        print(f\"  API Version: {self.azure_api_version}\")\n",
    "        print(f\"  Service ID: {self.service_id}\")\n",
    "        print(f\"  API Key: {'*' * 20 + self.azure_api_key[-4:] if self.azure_api_key else 'Not set'}\")\n",
    "\n",
    "# Initialize configuration\n",
    "try:\n",
    "    sk_config = SemanticKernelConfig()\n",
    "    sk_config.display_config()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load configuration: {e}\")\n",
    "    print(\"\\nPlease ensure you have a .env file with the following variables:\")\n",
    "    print(\"- AZURE_OPENAI_API_KEY\")\n",
    "    print(\"- AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"- AZURE_OPENAI_CHAT_DEPLOYMENT_NAME (optional, defaults to gpt-4o-mini)\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.1 Basic Chat and Kernel Configuration\n\nSemantic Kernel uses a dependency injection pattern with services registered in the kernel. This provides strong typing and better enterprise patterns.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import semantic_kernel as sk\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\nfrom semantic_kernel.contents import ChatHistory\n\n# Initialize the kernel - central orchestrator for all SK operations\nkernel = sk.Kernel()\n\n# Configure Azure OpenAI chat completion service with dependency injection\nazure_chat_service = AzureChatCompletion(\n    service_id=sk_config.service_id,\n    deployment_name=sk_config.azure_deployment,\n    endpoint=sk_config.azure_endpoint,\n    api_key=sk_config.azure_api_key,\n    api_version=sk_config.azure_api_version\n)\n\n# Register the service with the kernel (dependency injection pattern)\nkernel.add_service(azure_chat_service)\n\nprint(\"üîß Kernel Configuration:\")\nprint(f\"  Services registered: {len(kernel.services)}\")\nprint(f\"  Chat service ID: {sk_config.service_id}\")\n\nasync def demonstrate_basic_chat():\n    \"\"\"Demonstrates basic chat functionality with proper settings\"\"\"\n    \n    # Create chat history for conversation context\n    history = ChatHistory()\n    history.add_system_message(\"You are a helpful assistant who provides concise, step-by-step answers.\")\n    history.add_user_message(\"What is the capital of France?\")\n    \n    # Create execution settings - required for all SK operations\n    execution_settings = AzureChatPromptExecutionSettings(\n        service_id=sk_config.service_id,\n        max_tokens=150,\n        temperature=0.7\n    )\n    \n    print(\"üí¨ Basic Chat Example:\")\n    print(\"User > What is the capital of France?\")\n    \n    # Execute the chat completion\n    response = await azure_chat_service.get_chat_message_content(\n        chat_history=history, \n        settings=execution_settings\n    )\n    \n    print(f\"Assistant > {response.content}\")\n    \n    # Demonstrate conversation continuation\n    history.add_assistant_message(response.content)\n    history.add_user_message(\"What language do they speak there?\")\n    \n    print(\"\\\\nUser > What language do they speak there?\")\n    \n    response2 = await azure_chat_service.get_chat_message_content(\n        chat_history=history,\n        settings=execution_settings\n    )\n    \n    print(f\"Assistant > {response2.content}\")\n\n# Execute the demonstration\nawait demonstrate_basic_chat()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.2 Plugin Architecture and Sequential Orchestration\n\nSemantic Kernel's plugin system provides a structured approach to building reusable components. Unlike LangChain's composition, SK uses explicit orchestration.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create semantic functions from prompts (SK's equivalent to LangChain chains)\n# These are registered as plugins in the kernel\n\n# Plugin 1: Company Naming\ncompany_naming_prompt = \"\"\"\nWhat is a good name for a company that makes {{$input}}? \nProvide just the company name, nothing else.\n\"\"\"\n\nnaming_function = kernel.create_function_from_prompt(\n    function_name=\"generate_name\", \n    plugin_name=\"MarketingPlugin\", \n    prompt=company_naming_prompt,\n    description=\"Generates creative company names for products\"\n)\n\n# Plugin 2: Catchphrase Generation  \ncatchphrase_prompt = \"\"\"\nWrite a creative, memorable catchphrase for the following company: {{$input}}\nMake it catchy and professional. Provide just the catchphrase, nothing else.\n\"\"\"\n\ncatchphrase_function = kernel.create_function_from_prompt(\n    function_name=\"generate_catchphrase\", \n    plugin_name=\"MarketingPlugin\", \n    prompt=catchphrase_prompt,\n    description=\"Creates marketing catchphrases for companies\"\n)\n\nprint(\"üîå Plugins Registered:\")\nprint(f\"  Total plugins: {len(kernel.plugins)}\")\nfor plugin_name, plugin in kernel.plugins.items():\n    print(f\"  - {plugin_name}: {len(plugin.functions)} functions\")\n    for func_name in plugin.functions:\n        print(f\"    ‚Ä¢ {func_name}\")\n\nasync def demonstrate_orchestration():\n    \"\"\"Demonstrates explicit orchestration - SK's approach to sequential processing\"\"\"\n    \n    product = \"colorful, eco-friendly socks\"\n    print(f\"\\\\nüéØ Input product: {product}\")\n    print(\"\\\\nüîó Running Sequential Orchestration...\")\n    \n    # Step 1: Generate company name (explicit orchestration)\n    print(\"\\\\nüìù Step 1: Generating company name...\")\n    try:\n        name_result = await kernel.invoke(naming_function, sk.KernelArguments(input=product))\n        company_name = str(name_result).strip()\n        print(f\"   Result: {company_name}\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return\n    \n    # Step 2: Generate catchphrase using the generated name\n    print(\"\\\\nüé® Step 2: Generating catchphrase...\")\n    try:\n        catchphrase_result = await kernel.invoke(catchphrase_function, sk.KernelArguments(input=company_name))\n        catchphrase = str(catchphrase_result).strip()\n        print(f\"   Result: {catchphrase}\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return\n    \n    # Display final results\n    print(\"\\\\n\" + \"=\"*50)\n    print(\"‚úÖ ORCHESTRATION COMPLETE\")\n    print(\"=\"*50)\n    print(f\"Product: {product}\")\n    print(f\"Company Name: {company_name}\")\n    print(f\"Catchphrase: {catchphrase}\")\n    print(\"=\"*50)\n    \n    return {\n        \"product\": product,\n        \"company_name\": company_name, \n        \"catchphrase\": catchphrase\n    }\n\n# Execute the orchestration\nresult = await demonstrate_orchestration()\n\n# Demonstrate plugin reusability\nprint(\"\\\\nüîÑ Demonstrating Plugin Reusability...\")\ntest_products = [\"smart home devices\", \"artisanal coffee beans\"]\n\nfor product in test_products:\n    print(f\"\\\\n‚Üí Testing with: {product}\")\n    name_result = await kernel.invoke(naming_function, sk.KernelArguments(input=product))\n    print(f\"  Generated name: {name_result}\")"
  },
  {
   "cell_type": "markdown",
   "id": "ynixtlvl6i",
   "source": "### 2.3 Native Function Plugins\n\nSK's strength lies in its ability to combine AI with traditional code through native function plugins. This demonstrates the hybrid AI + code approach.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6alcrpf8no5",
   "source": "### 2.4 Automatic Function Calling (Basic Agent Behavior)\n\nSemantic Kernel's automatic function calling provides agent-like behavior through structured function invocation. This demonstrates single-agent capabilities before exploring the Agent Framework.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary: Semantic Kernel Fundamentals\n\nThis notebook covered Semantic Kernel's core concepts using enterprise-ready patterns:\n\n### Key Concepts Learned:\n1. **Kernel Architecture**: Central orchestrator with dependency injection and service registration\n2. **Plugin System**: Structured approach combining semantic functions (AI) and native functions (code)\n3. **Explicit Orchestration**: Programmatic control flow rather than compositional chaining\n4. **Function Calling**: Automatic function selection with typed interfaces and safety\n\n### Semantic Kernel's Philosophy:\n- **\"Orchestrate Everything\"**: Structured orchestration with clear separation of concerns\n- **Hybrid AI + Code**: Seamless integration of LLM capabilities with traditional programming\n- **Enterprise Patterns**: Dependency injection, typed interfaces, and governance-ready architecture\n- **Plugin Ecosystem**: Reusable, discoverable functions with proper metadata\n\n### SK vs LangChain Comparison:\n| Aspect | LangChain (LCEL) | Semantic Kernel |\n|--------|------------------|-----------------|\n| **Composition** | Pipe operators (`\\|`) | Explicit `kernel.invoke()` calls |\n| **Functions** | Tools with dynamic binding | Plugins with typed interfaces |\n| **Flow Control** | Implicit through chains | Explicit orchestration code |\n| **Enterprise Focus** | Community-driven | Microsoft enterprise patterns |\n\n### Next Steps:\n- **Multi-Agent Systems**: See `4_semantic_kernel_agents.ipynb` for Agent Framework\n- **Advanced Plugins**: Memory integration, planning, and complex workflows\n- **Production Deployment**: Azure integration, monitoring, and governance\n\n### Production Considerations:\n- Leverage dependency injection for testability and maintainability\n- Use typed interfaces for better IDE support and error prevention\n- Implement proper error handling and logging throughout the kernel\n- Consider plugin security and validation for production deployments\n- Take advantage of Azure ecosystem integration for enterprise features",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# This cell is being removed - duplicate content"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# This cell is being removed - redundant summary",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}