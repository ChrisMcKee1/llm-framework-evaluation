{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: LangChain Multi-Agent Systems with LangGraph\n",
    "\n",
    "This notebook demonstrates LangGraph's powerful multi-agent capabilities. We'll explore state management, sequential workflows, and agent coordination that showcase LangChain's advanced orchestration features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Setting up the environment for LangGraph multi-agent workflows with Azure OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and configuration setup for LangGraph\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import TypedDict, Annotated, List, Dict, Any\n",
    "import operator\n",
    "\n",
    "# Import LangGraph and LangChain components\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.tools import tool\n",
    "\n",
    "class LangGraphConfig:\n",
    "    \"\"\"Configuration management for LangGraph multi-agent workflows\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        env_path = find_dotenv()\n",
    "        if env_path:\n",
    "            load_dotenv(env_path)\n",
    "            print(f\"✅ Loaded environment from: {env_path}\")\n",
    "        else:\n",
    "            warnings.warn(\"No .env file found. Using system environment variables only.\")\n",
    "        \n",
    "        self._load_azure_config()\n",
    "        self._validate_config()\n",
    "    \n",
    "    def _load_azure_config(self):\n",
    "        \"\"\"Load Azure OpenAI configuration from environment variables\"\"\"\n",
    "        self.azure_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "        self.azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "        self.azure_deployment = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME', 'gpt-4o-mini')\n",
    "        self.azure_api_version = os.getenv('AZURE_OPENAI_API_VERSION', '2024-05-01-preview')\n",
    "        self.tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "    \n",
    "    def _validate_config(self):\n",
    "        \"\"\"Validate critical configuration\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if not self.azure_api_key:\n",
    "            errors.append(\"AZURE_OPENAI_API_KEY is required\")\n",
    "        \n",
    "        if not self.azure_endpoint:\n",
    "            errors.append(\"AZURE_OPENAI_ENDPOINT is required\")\n",
    "        \n",
    "        if errors:\n",
    "            raise ValueError(f\"Configuration errors: {', '.join(errors)}\")\n",
    "        \n",
    "        print(\"✅ All LangGraph configuration validated successfully\")\n",
    "    \n",
    "    def create_llm(self, temperature: float = 0.7) -> AzureChatOpenAI:\n",
    "        \"\"\"Create an Azure OpenAI LLM instance with the configuration\"\"\"\n",
    "        return AzureChatOpenAI(\n",
    "            azure_deployment=self.azure_deployment,\n",
    "            api_version=self.azure_api_version,\n",
    "            temperature=temperature,\n",
    "            azure_endpoint=self.azure_endpoint,\n",
    "            api_key=self.azure_api_key\n",
    "        )\n",
    "\n",
    "# Initialize configuration\n",
    "config = LangGraphConfig()\n",
    "print(f\"🧠 LangGraph Configuration Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.1 State Management and Basic Graph\n\nLangGraph's core strength is state management across multiple agents. Let's start by understanding the state structure and creating our first graph.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom state for our multi-agent workflow\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"State structure for research workflow\"\"\"\n",
    "    messages: Annotated[List[Any], operator.add]  # Message history\n",
    "    topic: str  # Research topic\n",
    "    research_data: str  # Collected research\n",
    "    analysis: str  # Analysis results\n",
    "    final_report: str  # Final output\n",
    "    current_agent: str  # Track current agent\n",
    "\n",
    "# Create specialized LLM instances for different agents\n",
    "researcher_llm = config.create_llm(temperature=0.3)  # Lower temp for factual research\n",
    "analyst_llm = config.create_llm(temperature=0.5)     # Medium temp for analysis\n",
    "writer_llm = config.create_llm(temperature=0.7)      # Higher temp for creative writing\n",
    "\n",
    "# Define tools for our agents\n",
    "@tool\n",
    "def research_tool(query: str) -> str:\n",
    "    \"\"\"Simulated research tool that returns research data\"\"\"\n",
    "    research_results = {\n",
    "        \"artificial intelligence\": \"AI is rapidly advancing with developments in LLMs, computer vision, and robotics. Key trends include multimodal AI, edge computing integration, and ethical AI frameworks.\",\n",
    "        \"climate change\": \"Climate change continues to be a critical global challenge. Recent data shows accelerating ice melt, rising sea levels, and increased frequency of extreme weather events.\",\n",
    "        \"quantum computing\": \"Quantum computing is approaching practical applications. IBM, Google, and other companies have achieved quantum advantage in specific tasks, with focus on error correction and scaling.\"\n",
    "    }\n",
    "    \n",
    "    for topic, data in research_results.items():\n",
    "        if topic.lower() in query.lower():\n",
    "            return f\"Research findings on {topic}: {data}\"\n",
    "    \n",
    "    return f\"Limited research data available for: {query}\"\n",
    "\n",
    "@tool  \n",
    "def analysis_tool(data: str) -> str:\n",
    "    \"\"\"Simulated analysis tool that processes research data\"\"\"\n",
    "    if \"AI\" in data or \"artificial intelligence\" in data.lower():\n",
    "        return \"Analysis: AI sector shows exponential growth with significant investment in enterprise applications and ethical frameworks.\"\n",
    "    elif \"climate\" in data.lower():\n",
    "        return \"Analysis: Climate data indicates urgent need for mitigation strategies and adaptation measures across all sectors.\"\n",
    "    elif \"quantum\" in data.lower():\n",
    "        return \"Analysis: Quantum computing approaching commercialization with potential disruption in cryptography, optimization, and simulation.\"\n",
    "    else:\n",
    "        return f\"General analysis: The provided data suggests emerging trends that require further investigation.\"\n",
    "\n",
    "print(\"🤖 Multi-Agent System Initialized\")\n",
    "print(\"   👥 Agents: Researcher, Analyst, Writer\")\n",
    "print(\"   🧠 LLMs configured with specialized temperatures\")\n",
    "print(\"   🛠️ Tools: research_tool, analysis_tool\")\n",
    "print(\"   📊 State management ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.2 Agent Function Definitions\n\nEach agent function operates on the shared state and performs its specialized role.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Research agent that gathers information on the topic\"\"\"\n",
    "    print(f\"🔍 Researcher Agent activated for topic: {state['topic']}\")\n",
    "    \n",
    "    # Use the research tool to gather information\n",
    "    research_data = research_tool.invoke(state['topic'])\n",
    "    \n",
    "    print(f\"   📊 Research completed: {len(research_data)} characters of data\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"research_data\": research_data,\n",
    "        \"current_agent\": \"researcher\",\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=f\"Research completed on {state['topic']}.\")]\n",
    "    }\n",
    "\n",
    "def analyst_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Analyst agent that processes and analyzes research data\"\"\"\n",
    "    print(f\"📈 Analyst Agent activated\")\n",
    "    \n",
    "    if not state.get(\"research_data\"):\n",
    "        print(\"   ⚠️ No research data available\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"analysis\": \"No research data available for analysis\",\n",
    "            \"current_agent\": \"analyst\"\n",
    "        }\n",
    "    \n",
    "    # Use the analysis tool to process research data\n",
    "    analysis_result = analysis_tool.invoke(state[\"research_data\"])\n",
    "    \n",
    "    print(f\"   📊 Analysis completed: {len(analysis_result)} characters\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"analysis\": analysis_result,\n",
    "        \"current_agent\": \"analyst\",\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"Analysis phase completed.\")]\n",
    "    }\n",
    "\n",
    "def writer_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Writer agent that creates the final report\"\"\"\n",
    "    print(f\"✍️ Writer Agent activated\")\n",
    "    \n",
    "    if not state.get(\"research_data\") or not state.get(\"analysis\"):\n",
    "        print(\"   ⚠️ Insufficient data for writing\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"final_report\": \"Insufficient data to create report\",\n",
    "            \"current_agent\": \"writer\"\n",
    "        }\n",
    "    \n",
    "    # Create comprehensive report using LLM\n",
    "    writing_prompt = ChatPromptTemplate.from_template(\n",
    "        \"You are a skilled technical writer. Create a comprehensive report based on:\\n\\n\"\n",
    "        \"RESEARCH DATA:\\n{research_data}\\n\\n\"\n",
    "        \"ANALYSIS:\\n{analysis}\\n\\n\"\n",
    "        \"Create a well-structured report with executive summary, key findings, and recommendations.\"\n",
    "    )\n",
    "    \n",
    "    writing_chain = writing_prompt | writer_llm | StrOutputParser()\n",
    "    \n",
    "    final_report = writing_chain.invoke({\n",
    "        \"research_data\": state[\"research_data\"],\n",
    "        \"analysis\": state[\"analysis\"]\n",
    "    })\n",
    "    \n",
    "    print(f\"   📝 Report completed: {len(final_report)} characters\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"final_report\": final_report,\n",
    "        \"current_agent\": \"writer\",\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"Final report completed.\")]\n",
    "    }\n",
    "\n",
    "print(\"🤖 Agent Functions Defined:\")\n",
    "print(\"   🔍 researcher_agent: Gathers information using research tools\")\n",
    "print(\"   📈 analyst_agent: Processes data using analysis tools\")\n",
    "print(\"   ✍️ writer_agent: Creates final reports from research and analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.3 Building the LangGraph Workflow\n\nNow let's create the actual LangGraph workflow that connects our agents through a state graph.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LangGraph workflow\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "# Add nodes (agents) to the graph\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"analyst\", analyst_agent)\n",
    "workflow.add_node(\"writer\", writer_agent)\n",
    "\n",
    "# Define the workflow edges (sequence)\n",
    "workflow.set_entry_point(\"researcher\")\n",
    "workflow.add_edge(\"researcher\", \"analyst\")\n",
    "workflow.add_edge(\"analyst\", \"writer\")\n",
    "workflow.add_edge(\"writer\", END)\n",
    "\n",
    "# Compile the graph into a runnable workflow\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"🔗 LangGraph Workflow Created:\")\n",
    "print(\"   📊 State: ResearchState with message history and data tracking\")\n",
    "print(\"   🔀 Flow: Researcher → Analyst → Writer → END\")\n",
    "print(\"   🤖 Multi-agent coordination with shared state\")\n",
    "\n",
    "# Visualize the workflow structure\n",
    "print(\"\\n📋 Workflow Structure:\")\n",
    "print(\"   1. 🔍 Researcher: Gathers information using research tools\")\n",
    "print(\"   2. 📈 Analyst: Processes and analyzes the research data\")\n",
    "print(\"   3. ✍️ Writer: Creates comprehensive report from findings\")\n",
    "print(\"   4. ✅ END: Final state with complete research report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.4 Executing the Multi-Agent Workflow\n\nLet's run our LangGraph workflow with a research topic and see the agents collaborate.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_research_workflow(topic: str):\n",
    "    \"\"\"Execute the multi-agent research workflow\"\"\"\n",
    "    \n",
    "    print(f\"🚀 Starting Multi-Agent Research Workflow\")\n",
    "    print(f\"📝 Topic: {topic}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize the state\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=f\"Research topic: {topic}\")],\n",
    "        \"topic\": topic,\n",
    "        \"research_data\": \"\",\n",
    "        \"analysis\": \"\",\n",
    "        \"final_report\": \"\",\n",
    "        \"current_agent\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Execute the workflow\n",
    "    try:\n",
    "        final_state = await app.ainvoke(initial_state)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✅ WORKFLOW COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\n📊 Research Data ({len(final_state['research_data'])} chars):\")\n",
    "        print(final_state['research_data'][:200] + \"...\")\n",
    "        \n",
    "        print(f\"\\n📈 Analysis ({len(final_state['analysis'])} chars):\")\n",
    "        print(final_state['analysis'])\n",
    "        \n",
    "        print(f\"\\n📝 Final Report ({len(final_state['final_report'])} chars):\")\n",
    "        print(final_state['final_report'][:300] + \"...\")\n",
    "        \n",
    "        return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Workflow error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the workflow with different topics\n",
    "test_topics = [\n",
    "    \"artificial intelligence\",\n",
    "    \"climate change\", \n",
    "    \"quantum computing\"\n",
    "]\n",
    "\n",
    "for topic in test_topics:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    result = await run_research_workflow(topic)\n",
    "    if result:\n",
    "        print(f\"✅ Successfully completed research on: {topic}\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to complete research on: {topic}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: LangGraph Multi-Agent Systems\n",
    "\n",
    "This notebook demonstrated LangGraph's advanced multi-agent capabilities:\n",
    "\n",
    "### Key Concepts Learned:\n",
    "1. **State Management**: Shared state across multiple agents with TypedDict definitions\n",
    "2. **Agent Coordination**: Sequential workflow with specialized agent roles\n",
    "3. **Graph Construction**: Building workflows with nodes (agents) and edges (transitions)\n",
    "4. **Tool Integration**: Agents using tools within the multi-agent context\n",
    "\n",
    "### LangGraph's Advantages:\n",
    "- **Stateful Workflows**: Persistent state across agent interactions\n",
    "- **Complex Orchestration**: Support for cycles, conditionals, and dynamic routing\n",
    "- **Agent Specialization**: Different LLM configurations per agent role\n",
    "- **Scalable Architecture**: Easy to add new agents and modify workflows\n",
    "\n",
    "### LangGraph vs Traditional Agents:\n",
    "| Aspect | Traditional Agents | LangGraph |\n",
    "|--------|-------------------|----------|\n",
    "| **State Management** | Limited to single agent | Shared across all agents |\n",
    "| **Workflow Control** | Linear or simple branching | Complex graphs with cycles |\n",
    "| **Agent Coordination** | Manual orchestration | Automatic state-driven flow |\n",
    "| **Debugging** | Limited visibility | Full state inspection at each step |\n",
    "\n",
    "### Next Steps:\n",
    "- **Supervisor Patterns**: Central agent coordinating multiple specialists\n",
    "- **Conditional Routing**: Dynamic agent selection based on state\n",
    "- **Human-in-the-Loop**: Interactive workflows with user intervention\n",
    "- **Memory Integration**: Persistent memory across workflow executions\n",
    "\n",
    "### Production Considerations:\n",
    "- Implement proper error handling and recovery mechanisms\n",
    "- Add logging and monitoring for multi-agent workflows\n",
    "- Consider token usage optimization across multiple LLM calls\n",
    "- Design state schemas for complex, real-world use cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}